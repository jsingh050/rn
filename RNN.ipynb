{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "My code was adapted from Dr. Xiang Zhang (xiang_zhang@hms.harvard.edu), Prof. Lina Yao (lina.yao@unsw.edu.au)\n",
        "Citations for some of their materials can be provided here\n",
        "article{zhang2020survey,\n",
        "  title={A survey on deep learning-based non-invasive brain signals: recent advances and new frontiers},\n",
        "  author={Zhang, Xiang and Yao, Lina and Wang, Xianzhi and Monaghan, Jessica JM and Mcalpine, David and Zhang, Yu},\n",
        "  journal={Journal of Neural Engineering},\n",
        "  year={2020},\n",
        "  publisher={IOP Publishing}\n",
        "}\n",
        "\n",
        "@book{zhang2021deep,\n",
        "  title={Deep Learning for EEG-based Brain-Computer Interface: Representations, Algorithms and Applications},\n",
        "  author={Zhang, Xiang and Yao, Lina},\n",
        "  year={2021},\n",
        "  publisher={World Scientific Publishing}\n",
        "}"
      ],
      "metadata": {
        "id": "PkWHkqUJMK6g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com//xiangzhang1015/Deep-Learning-for-BCI.git\n",
        "%cd Deep-Learning-for-BCI/dataset\n",
        "!ls\n",
        "\n",
        "!mkdir -p unzipped_data\n",
        "!unzip \"*.zip\" -d /content/Deep-Learning-for-BCI/dataset/unzipped_data\n",
        "\n",
        "\n",
        "!ls /content/Deep-Learning-for-BCI/dataset/unzipped_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct68es_kMYgW",
        "outputId": "e9714f51-f3fd-40b7-9e48-d3bac38649d3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep-Learning-for-BCI'...\n",
            "remote: Enumerating objects: 448, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 448 (delta 0), reused 1 (delta 0), pack-reused 445 (from 1)\u001b[K\n",
            "Receiving objects: 100% (448/448), 2.14 GiB | 25.37 MiB/s, done.\n",
            "Resolving deltas: 100% (188/188), done.\n",
            "Updating files: 100% (137/137), done.\n",
            "/content/Deep-Learning-for-BCI/dataset\n",
            "100.zip  10.zip  1.zip\t 29.zip  38.zip  47.zip  56.zip  65.zip  74.zip  83.zip  92.zip\n",
            "101.zip  11.zip  20.zip  2.zip\t 39.zip  48.zip  57.zip  66.zip  75.zip  84.zip  93.zip\n",
            "102.zip  12.zip  21.zip  30.zip  3.zip\t 49.zip  58.zip  67.zip  76.zip  85.zip  94.zip\n",
            "103.zip  13.zip  22.zip  31.zip  40.zip  4.zip\t 59.zip  68.zip  77.zip  86.zip  95.zip\n",
            "104.zip  14.zip  23.zip  32.zip  41.zip  50.zip  5.zip\t 69.zip  78.zip  87.zip  96.zip\n",
            "105.zip  15.zip  24.zip  33.zip  42.zip  51.zip  60.zip  6.zip\t 79.zip  88.zip  97.zip\n",
            "106.zip  16.zip  25.zip  34.zip  43.zip  52.zip  61.zip  70.zip  7.zip\t 89.zip  98.zip\n",
            "107.zip  17.zip  26.zip  35.zip  44.zip  53.zip  62.zip  71.zip  80.zip  8.zip\t 99.zip\n",
            "108.zip  18.zip  27.zip  36.zip  45.zip  54.zip  63.zip  72.zip  81.zip  90.zip  9.zip\n",
            "109.zip  19.zip  28.zip  37.zip  46.zip  55.zip  64.zip  73.zip  82.zip  91.zip  notes\n",
            "Archive:  79.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/79.npy  \n",
            "\n",
            "Archive:  49.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/49.npy  \n",
            "\n",
            "Archive:  2.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/2.npy  \n",
            "\n",
            "Archive:  85.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/85.npy  \n",
            "\n",
            "Archive:  106.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/106.npy  \n",
            "\n",
            "Archive:  100.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/100.npy  \n",
            "\n",
            "Archive:  69.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/69.npy  \n",
            "\n",
            "Archive:  50.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/50.npy  \n",
            "\n",
            "Archive:  8.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/8.npy  \n",
            "\n",
            "Archive:  21.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/21.npy  \n",
            "\n",
            "Archive:  90.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/90.npy  \n",
            "\n",
            "Archive:  33.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/33.npy  \n",
            "\n",
            "Archive:  23.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/23.npy  \n",
            "\n",
            "Archive:  19.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/19.npy  \n",
            "\n",
            "Archive:  86.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/86.npy  \n",
            "\n",
            "Archive:  9.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/9.npy  \n",
            "\n",
            "Archive:  12.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/12.npy  \n",
            "\n",
            "Archive:  46.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/46.npy  \n",
            "\n",
            "Archive:  93.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/93.npy  \n",
            "\n",
            "Archive:  32.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/32.npy  \n",
            "\n",
            "Archive:  71.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/71.npy  \n",
            "\n",
            "Archive:  54.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/54.npy  \n",
            "\n",
            "Archive:  35.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/35.npy  \n",
            "\n",
            "Archive:  91.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/91.npy  \n",
            "\n",
            "Archive:  61.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/61.npy  \n",
            "\n",
            "Archive:  52.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/52.npy  \n",
            "\n",
            "Archive:  59.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/59.npy  \n",
            "\n",
            "Archive:  48.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/48.npy  \n",
            "\n",
            "Archive:  98.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/98.npy  \n",
            "\n",
            "Archive:  104.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/104.npy  \n",
            "\n",
            "Archive:  1.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/1.npy  \n",
            "\n",
            "Archive:  47.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/47.npy  \n",
            "\n",
            "Archive:  108.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/108.npy  \n",
            "\n",
            "Archive:  73.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/73.npy  \n",
            "\n",
            "Archive:  25.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/25.npy  \n",
            "\n",
            "Archive:  99.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/99.npy  \n",
            "\n",
            "Archive:  14.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/14.npy  \n",
            "\n",
            "Archive:  53.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/53.npy  \n",
            "\n",
            "Archive:  36.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/36.npy  \n",
            "\n",
            "Archive:  70.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/70.npy  \n",
            "\n",
            "Archive:  58.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/58.npy  \n",
            "\n",
            "Archive:  13.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/13.npy  \n",
            "\n",
            "Archive:  39.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/39.npy  \n",
            "\n",
            "Archive:  76.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/76.npy  \n",
            "\n",
            "Archive:  75.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/75.npy  \n",
            "\n",
            "Archive:  97.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/97.npy  \n",
            "\n",
            "Archive:  74.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/74.npy  \n",
            "\n",
            "Archive:  77.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/77.npy  \n",
            "\n",
            "Archive:  84.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/84.npy  \n",
            "\n",
            "Archive:  87.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/87.npy  \n",
            "\n",
            "Archive:  30.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/30.npy  \n",
            "\n",
            "Archive:  20.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/20.npy  \n",
            "\n",
            "Archive:  68.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/68.npy  \n",
            "\n",
            "Archive:  44.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/44.npy  \n",
            "\n",
            "Archive:  101.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/101.npy  \n",
            "\n",
            "Archive:  94.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/94.npy  \n",
            "\n",
            "Archive:  60.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/60.npy  \n",
            "\n",
            "Archive:  15.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/15.npy  \n",
            "\n",
            "Archive:  62.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/62.npy  \n",
            "\n",
            "Archive:  16.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/16.npy  \n",
            "\n",
            "Archive:  109.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/109.npy  \n",
            "\n",
            "Archive:  11.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/11.npy  \n",
            "\n",
            "Archive:  5.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/5.npy  \n",
            "\n",
            "Archive:  34.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/34.npy  \n",
            "\n",
            "Archive:  63.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/63.npy  \n",
            "\n",
            "Archive:  78.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/78.npy  \n",
            "\n",
            "Archive:  42.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/42.npy  \n",
            "\n",
            "Archive:  57.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/57.npy  \n",
            "\n",
            "Archive:  107.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/107.npy  \n",
            "\n",
            "Archive:  95.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/95.npy  \n",
            "\n",
            "Archive:  102.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/102.npy  \n",
            "\n",
            "Archive:  82.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/82.npy  \n",
            "\n",
            "Archive:  40.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/40.npy  \n",
            "\n",
            "Archive:  103.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/103.npy  \n",
            "\n",
            "Archive:  18.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/18.npy  \n",
            "\n",
            "Archive:  6.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/6.npy  \n",
            "\n",
            "Archive:  38.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/38.npy  \n",
            "\n",
            "Archive:  51.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/51.npy  \n",
            "\n",
            "Archive:  64.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/64.npy  \n",
            "\n",
            "Archive:  105.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/105.npy  \n",
            "\n",
            "Archive:  28.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/28.npy  \n",
            "\n",
            "Archive:  89.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/89.npy  \n",
            "\n",
            "Archive:  72.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/72.npy  \n",
            "\n",
            "Archive:  66.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/66.npy  \n",
            "\n",
            "Archive:  29.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/29.npy  \n",
            "\n",
            "Archive:  31.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/31.npy  \n",
            "\n",
            "Archive:  24.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/24.npy  \n",
            "\n",
            "Archive:  65.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/65.npy  \n",
            "\n",
            "Archive:  22.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/22.npy  \n",
            "\n",
            "Archive:  3.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/3.npy  \n",
            "\n",
            "Archive:  56.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/56.npy  \n",
            "\n",
            "Archive:  45.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/45.npy  \n",
            "\n",
            "Archive:  80.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/80.npy  \n",
            "\n",
            "Archive:  41.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/41.npy  \n",
            "\n",
            "Archive:  7.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/7.npy  \n",
            "\n",
            "Archive:  88.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/88.npy  \n",
            "\n",
            "Archive:  55.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/55.npy  \n",
            "\n",
            "Archive:  17.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/17.npy  \n",
            "\n",
            "Archive:  27.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/27.npy  \n",
            "\n",
            "Archive:  96.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/96.npy  \n",
            "\n",
            "Archive:  92.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/92.npy  \n",
            "\n",
            "Archive:  26.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/26.npy  \n",
            "\n",
            "Archive:  37.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/37.npy  \n",
            "\n",
            "Archive:  67.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/67.npy  \n",
            "\n",
            "Archive:  43.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/43.npy  \n",
            "\n",
            "Archive:  10.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/10.npy  \n",
            "\n",
            "Archive:  81.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/81.npy  \n",
            "\n",
            "Archive:  83.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/83.npy  \n",
            "\n",
            "Archive:  4.zip\n",
            "  inflating: /content/Deep-Learning-for-BCI/dataset/unzipped_data/4.npy  \n",
            "\n",
            "109 archives were successfully processed.\n",
            "100.npy  10.npy  1.npy\t 29.npy  38.npy  47.npy  56.npy  65.npy  74.npy  83.npy  92.npy\n",
            "101.npy  11.npy  20.npy  2.npy\t 39.npy  48.npy  57.npy  66.npy  75.npy  84.npy  93.npy\n",
            "102.npy  12.npy  21.npy  30.npy  3.npy\t 49.npy  58.npy  67.npy  76.npy  85.npy  94.npy\n",
            "103.npy  13.npy  22.npy  31.npy  40.npy  4.npy\t 59.npy  68.npy  77.npy  86.npy  95.npy\n",
            "104.npy  14.npy  23.npy  32.npy  41.npy  50.npy  5.npy\t 69.npy  78.npy  87.npy  96.npy\n",
            "105.npy  15.npy  24.npy  33.npy  42.npy  51.npy  60.npy  6.npy\t 79.npy  88.npy  97.npy\n",
            "106.npy  16.npy  25.npy  34.npy  43.npy  52.npy  61.npy  70.npy  7.npy\t 89.npy  98.npy\n",
            "107.npy  17.npy  26.npy  35.npy  44.npy  53.npy  62.npy  71.npy  80.npy  8.npy\t 99.npy\n",
            "108.npy  18.npy  27.npy  36.npy  45.npy  54.npy  63.npy  72.npy  81.npy  90.npy  9.npy\n",
            "109.npy  19.npy  28.npy  37.npy  46.npy  55.npy  64.npy  73.npy  82.npy  91.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LSTM**\n",
        "\n",
        "Long short-term memory (LSTM) an RNN architecture which has an input gate, an output gate and a forget gate; the cell remembers values over arbitrary time intervals and the three gates regulate the flow of information into and out of the cell. This code aims to extract time-series information hidden from EEG signals. My goal was to just play around with making an RNN since a CNN might take too much time and this code was SO well documented I kind of got to annotate and run step by step, then I got to debug, then (time-depending) I will make tweaks to the code. The goal of this was just to be an exploration.\n",
        "\n",
        "Adapted from: Dr. Xiang Zhang (xiang_zhang@hms.harvard.edu), Prof. Lina Yao (lina.yao@unsw.edu.au) at https://github.com/xiangzhang1015/Deep-Learning-for-BCI."
      ],
      "metadata": {
        "id": "enJZrKDTNYkR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#what the OG team did to load their data\n",
        "#  dataset_1 = np.load('1.npy')\n",
        "# print('dataset_1 shape:', dataset_1.shape)\n"
      ],
      "metadata": {
        "id": "aW7bkjWhP9uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import libraries and load the dataset from github via cloning (I actually have never done this!)\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report\n",
        "import os\n",
        "\n",
        "# Path to the directory containing .npy files\n",
        "data_path = '/content/Deep-Learning-for-BCI/dataset/unzipped_data'\n",
        "\n",
        "# List all .npy files in the directory\n",
        "file_list = [file for file in os.listdir(data_path) if file.endswith('.npy')]\n",
        "\n",
        "# Load all .npy files into a list\n",
        "datasets = []\n",
        "for file_name in file_list:\n",
        "    file_path = os.path.join(data_path, file_name)\n",
        "    data = np.load(file_path)\n",
        "    datasets.append(data)\n",
        "    print(f'{file_name} shape: {data.shape}')\n",
        "\n",
        "print(f\"Total number of files loaded: {len(datasets)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqBMx06aNaof",
        "outputId": "8b52a846-b373-4710-a174-06ed8122c811"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.npy shape: (259520, 65)\n",
            "50.npy shape: (255680, 65)\n",
            "11.npy shape: (255680, 65)\n",
            "30.npy shape: (257600, 65)\n",
            "85.npy shape: (255680, 65)\n",
            "39.npy shape: (255680, 65)\n",
            "69.npy shape: (255520, 65)\n",
            "96.npy shape: (259520, 65)\n",
            "67.npy shape: (255680, 65)\n",
            "78.npy shape: (255680, 65)\n",
            "102.npy shape: (255840, 65)\n",
            "82.npy shape: (255680, 65)\n",
            "71.npy shape: (259520, 65)\n",
            "9.npy shape: (255680, 65)\n",
            "99.npy shape: (255680, 65)\n",
            "88.npy shape: (209984, 65)\n",
            "81.npy shape: (255680, 65)\n",
            "56.npy shape: (255680, 65)\n",
            "40.npy shape: (255680, 65)\n",
            "49.npy shape: (255680, 65)\n",
            "79.npy shape: (259520, 65)\n",
            "18.npy shape: (255680, 65)\n",
            "61.npy shape: (259520, 65)\n",
            "97.npy shape: (255520, 65)\n",
            "105.npy shape: (255680, 65)\n",
            "62.npy shape: (255680, 65)\n",
            "36.npy shape: (255680, 65)\n",
            "16.npy shape: (255680, 65)\n",
            "7.npy shape: (259520, 65)\n",
            "46.npy shape: (259520, 65)\n",
            "33.npy shape: (255680, 65)\n",
            "15.npy shape: (255680, 65)\n",
            "77.npy shape: (255680, 65)\n",
            "1.npy shape: (259520, 65)\n",
            "60.npy shape: (255680, 65)\n",
            "3.npy shape: (259520, 65)\n",
            "26.npy shape: (255680, 65)\n",
            "24.npy shape: (255680, 65)\n",
            "21.npy shape: (259520, 65)\n",
            "93.npy shape: (255680, 65)\n",
            "5.npy shape: (255680, 65)\n",
            "98.npy shape: (255680, 65)\n",
            "87.npy shape: (255680, 65)\n",
            "20.npy shape: (255680, 65)\n",
            "92.npy shape: (209984, 65)\n",
            "54.npy shape: (255680, 65)\n",
            "12.npy shape: (255680, 65)\n",
            "45.npy shape: (255680, 65)\n",
            "91.npy shape: (255680, 65)\n",
            "74.npy shape: (255840, 65)\n",
            "64.npy shape: (256160, 65)\n",
            "90.npy shape: (255680, 65)\n",
            "76.npy shape: (255680, 65)\n",
            "68.npy shape: (255680, 65)\n",
            "53.npy shape: (255680, 65)\n",
            "31.npy shape: (255680, 65)\n",
            "107.npy shape: (259520, 65)\n",
            "10.npy shape: (255680, 65)\n",
            "101.npy shape: (259520, 65)\n",
            "70.npy shape: (255680, 65)\n",
            "80.npy shape: (255680, 65)\n",
            "38.npy shape: (255680, 65)\n",
            "48.npy shape: (255680, 65)\n",
            "109.npy shape: (255520, 65)\n",
            "44.npy shape: (255680, 65)\n",
            "32.npy shape: (259520, 65)\n",
            "13.npy shape: (255680, 65)\n",
            "19.npy shape: (255680, 65)\n",
            "51.npy shape: (256480, 65)\n",
            "58.npy shape: (255680, 65)\n",
            "83.npy shape: (259520, 65)\n",
            "63.npy shape: (255680, 65)\n",
            "47.npy shape: (255680, 65)\n",
            "2.npy shape: (255680, 65)\n",
            "42.npy shape: (255680, 65)\n",
            "41.npy shape: (256320, 65)\n",
            "23.npy shape: (255680, 65)\n",
            "6.npy shape: (255680, 65)\n",
            "22.npy shape: (259520, 65)\n",
            "73.npy shape: (255680, 65)\n",
            "14.npy shape: (255520, 65)\n",
            "27.npy shape: (255680, 65)\n",
            "86.npy shape: (259520, 65)\n",
            "108.npy shape: (255680, 65)\n",
            "17.npy shape: (255680, 65)\n",
            "84.npy shape: (255680, 65)\n",
            "59.npy shape: (255680, 65)\n",
            "104.npy shape: (252960, 65)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QVuTBIjkQepS",
        "outputId": "ebeca2ca-a672-4fa4-cc57-871ae547f8a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Custom Dataset Class to Load Multiple .npy Files\n",
        "class NPYDataset(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.data_path = data_path\n",
        "        # List all .npy files in the directory\n",
        "        self.file_list = [file for file in os.listdir(data_path) if file.endswith('.npy')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.file_list)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Load each .npy file dynamically\n",
        "        file_name = self.file_list[index]\n",
        "        file_path = os.path.join(self.data_path, file_name)\n",
        "        data = np.load(file_path)  # Load numpy array\n",
        "\n",
        "        # Convert numpy array to PyTorch tensor\n",
        "        x_data = torch.tensor(data, dtype=torch.float32)\n",
        "\n",
        "        # Dummy label (replace this with actual labels if available)\n",
        "        y_label = torch.tensor(index % 2, dtype=torch.long)  # Example: Class 0 or 1\n",
        "\n",
        "        return x_data, y_label\n",
        "\n",
        "# Define a custom collate function to pad sequences\n",
        "def collate_fn(batch):\n",
        "    # Separate inputs and labels\n",
        "    x_batch, y_batch = zip(*batch)\n",
        "\n",
        "    # Pad the input sequences\n",
        "    x_batch_padded = pad_sequence(x_batch, batch_first=True, padding_value=0)\n",
        "\n",
        "    # Stack the labels\n",
        "    y_batch = torch.stack(y_batch, dim=0)\n",
        "\n",
        "    return x_batch_padded, y_batch\n",
        "\n",
        "# Path where your .npy files are stored\n",
        "data_path = '/content/Deep-Learning-for-BCI/dataset/unzipped_data'\n",
        "\n",
        "# Create an instance of the custom Dataset\n",
        "dataset = NPYDataset(data_path)\n",
        "\n",
        "# Use DataLoader to batch the data for training or testing\n",
        "# Use the custom collate_fn\n",
        "data_loader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "# Iterate through the DataLoader to load batches of data\n",
        "for x_batch, y_batch in data_loader:\n",
        "    print(\"Batch X shape:\", x_batch.shape)  # Shape of input data\n",
        "    print(\"Batch Y shape:\", y_batch.shape)  # Shape of labels\n",
        "    break  # Print the first batch and stop"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GrBU3hpCUBi0",
        "outputId": "c17fa233-02b4-435b-add1-4229138c86e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch X shape: torch.Size([16, 259520, 65])\n",
            "Batch Y shape: torch.Size([16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "dataset_1 = np.load(os.path.join(data_path, '1.npy'))\n",
        "print('The shape of Dataset_1:', dataset_1.shape)\n",
        "dataset_1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3qijIUktU8nm",
        "outputId": "ca2ecc37-096d-41a2-b787-d12b1c7813ab"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of Dataset_1: (259520, 65)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-16, -29,   2, ..., -11,  15,   0],\n",
              "       [-56, -54, -27, ...,   1,  21,   0],\n",
              "       [-55, -55, -29, ...,  18,  35,   0],\n",
              "       ...,\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9],\n",
              "       [  0,   0,   0, ...,   0,   0,   9]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if a GPU is available - I don't need to do this on colab but it's fine\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as Data\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import roc_auc_score,accuracy_score,classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import time\n",
        "\n",
        "with_gpu = torch.cuda.is_available()\n",
        "if with_gpu:\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "print('We are using %s now.' %device)\n",
        "\n",
        "# remove instance with label==10 (rest)\n",
        "removed_label = [2,3,4,5,6,7,8,9,10]  #2,3,4,5,\n",
        "for ll in removed_label:\n",
        "    id = dataset_1[:, -1]!=ll\n",
        "    dataset_1 = dataset_1[id]\n",
        "\n",
        "# data segmentation\n",
        "n_class = int(11-len(removed_label))  # 0~9 classes ('10:rest' is not considered)\n",
        "no_feature = 64  # the number of the features\n",
        "segment_length = 16  # selected time window; 16=160*0.1\n",
        "LR = 0.005  # learning rate\n",
        "EPOCH = 101\n",
        "n_hidden = 128  # number of neurons in hidden layer\n",
        "l2 = 0.001  # the coefficient of l2-norm regularization\n",
        "\n",
        "def one_hot(y_):\n",
        "    # Function to encode output labels from number indexes\n",
        "    # e.g.: [[5], [0], [3]] --> [[0, 0, 0, 0, 0, 1], [1, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0]]\n",
        "    y_ = y_.reshape(len(y_))\n",
        "    y_ = [int(xx) for xx in y_]\n",
        "    n_values = np.max(y_) + 1\n",
        "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]\n",
        "\n",
        "def extract(input, n_classes, n_fea, time_window, moving):\n",
        "    xx = input[:, :n_fea]\n",
        "    yy = input[:, n_fea:n_fea + 1]\n",
        "    new_x = []\n",
        "    new_y = []\n",
        "    number = int((xx.shape[0] / moving) - 1)\n",
        "    for i in range(number):\n",
        "        ave_y = np.average(yy[int(i * moving):int(i * moving + time_window)])\n",
        "        if ave_y in range(n_classes + 1):\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(ave_y)\n",
        "        else:\n",
        "            new_x.append(xx[int(i * moving):int(i * moving + time_window), :])\n",
        "            new_y.append(0)\n",
        "\n",
        "    new_x = np.array(new_x)\n",
        "    new_x = new_x.reshape([-1, n_fea * time_window])\n",
        "    new_y = np.array(new_y)\n",
        "    new_y.shape = [new_y.shape[0], 1]\n",
        "    data = np.hstack((new_x, new_y))\n",
        "    data = np.vstack((data, data[-1]))  # add the last sample again, to make the sample number round\n",
        "    return data\n",
        "\n",
        "data_seg = extract(dataset_1, n_classes=n_class, n_fea=no_feature, time_window=segment_length, moving=(segment_length/2))  # 50% overlapping\n",
        "print('After segmentation, the shape of the data:', data_seg.shape)\n",
        "\n",
        "# split training and test data\n",
        "no_longfeature = no_feature*segment_length\n",
        "data_seg_feature = data_seg[:, :no_longfeature]\n",
        "data_seg_label = data_seg[:, no_longfeature:no_longfeature+1]\n",
        "train_feature, test_feature, train_label, test_label = train_test_split(data_seg_feature, data_seg_label,test_size=0.2, shuffle=True)\n",
        "\n",
        "# normalization\n",
        "# before normalize reshape data back to raw data shape\n",
        "train_feature_2d = train_feature.reshape([-1, no_feature])\n",
        "test_feature_2d = test_feature.reshape([-1, no_feature])\n",
        "\n",
        "scaler1 = StandardScaler().fit(train_feature_2d)\n",
        "train_fea_norm1 = scaler1.transform(train_feature_2d) # normalize the training data\n",
        "test_fea_norm1 = scaler1.transform(test_feature_2d) # normalize the test data\n",
        "print('After normalization, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter normalization, the shape of test feature:', test_fea_norm1.shape)\n",
        "\n",
        "# after normalization, reshape data to 3d in order to feed in to LSTM\n",
        "train_fea_norm1 = train_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "test_fea_norm1 = test_fea_norm1.reshape([-1, segment_length, no_feature])\n",
        "print('After reshape, the shape of training feature:', train_fea_norm1.shape,\n",
        "      '\\nAfter reshape, the shape of test feature:', test_fea_norm1.shape)\n",
        "\n",
        "BATCH_size = test_fea_norm1.shape[0] # use test_data as batch size\n",
        "\n",
        "# feed data into dataloader\n",
        "train_fea_norm1 = torch.tensor(train_fea_norm1).to(device)\n",
        "train_label = torch.tensor(train_label.flatten()).to(device)\n",
        "train_data = Data.TensorDataset(train_fea_norm1, train_label)\n",
        "train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_size, shuffle=False)\n",
        "\n",
        "test_fea_norm1 = torch.tensor(test_fea_norm1).to(device)\n",
        "test_label = torch.tensor(test_label.flatten()).to(device)\n",
        "\n",
        "# classifier\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "\n",
        "        self.lstm_layer = nn.LSTM(\n",
        "            input_size=no_feature,\n",
        "            hidden_size=n_hidden,         # LSTM hidden unit\n",
        "            num_layers=2,           # number of LSTM layer\n",
        "            bias=True,\n",
        "            batch_first=True,       # input & output will has batch size as 1s dimension. e.g. (batch, segment_length, no_feature)\n",
        "        )\n",
        "\n",
        "        self.out = nn.Linear(n_hidden, n_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        r_out, (h_n, h_c) = self.lstm_layer(x.float(), None)\n",
        "        r_out = F.dropout(r_out, 0.3)\n",
        "\n",
        "        test_output = self.out(r_out[:, -1, :]) # choose r_out at the last time step\n",
        "        return test_output\n",
        "\n",
        "lstm = LSTM()\n",
        "lstm.to(device)\n",
        "print(lstm)\n",
        "\n",
        "optimizer = torch.optim.Adam(lstm.parameters(), lr=LR, weight_decay=l2)   # optimize all parameters\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "best_acc = []\n",
        "best_auc = []\n",
        "\n",
        "# training and testing\n",
        "start_time = time.perf_counter()\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (train_x, train_y) in enumerate(train_loader):\n",
        "\n",
        "        output = lstm(train_x)  # LSTM output of training data\n",
        "        loss = loss_func(output, train_y.long())  # cross entropy loss\n",
        "        optimizer.zero_grad()  # clear gradients for this training step\n",
        "        loss.backward()  # backpropagation, compute gradients\n",
        "        optimizer.step()  # apply gradients\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        test_output = lstm(test_fea_norm1)  # LSTM output of test data\n",
        "        test_loss = loss_func(test_output, test_label.long())\n",
        "\n",
        "        test_y_score = one_hot(test_label.data.cpu().numpy())  # .cpu() can be removed if your device is cpu.\n",
        "        pred_score = F.softmax(test_output, dim=1).data.cpu().numpy()  # normalize the output\n",
        "        auc_score = roc_auc_score(test_y_score, pred_score)\n",
        "\n",
        "        pred_y = torch.max(test_output, 1)[1].data.cpu().numpy()\n",
        "        pred_train = torch.max(output, 1)[1].data.cpu().numpy()\n",
        "\n",
        "        test_acc = accuracy_score(test_label.data.cpu().numpy(), pred_y)\n",
        "        train_acc = accuracy_score(train_y.data.cpu().numpy(), pred_train)\n",
        "\n",
        "\n",
        "        print('Epoch: ', epoch, '|train loss: %.4f' % loss.item(),\n",
        "              ' train ACC: %.4f' % train_acc, '| test loss: %.4f' % test_loss.item(),\n",
        "              'test ACC: %.4f' % test_acc, '| AUC: %.4f' % auc_score)\n",
        "        best_acc.append(test_acc)\n",
        "        best_auc.append(auc_score)\n",
        "\n",
        "current_time = time.perf_counter()\n",
        "running_time = current_time - start_time\n",
        "print(classification_report(test_label.data.cpu().numpy(), pred_y))\n",
        "print('BEST TEST ACC: {}, AUC: {}'.format(max(best_acc), max(best_auc)))\n",
        "print(\"Total Running Time: {} seconds\".format(round(running_time, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "f8HO7VmQPXBJ",
        "outputId": "e76c2d76-432b-4f7e-aefa-7bc0e5bd6382"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We are using cpu now.\n",
            "After segmentation, the shape of the data: (2440, 1025)\n",
            "After normalization, the shape of training feature: (31232, 64) \n",
            "After normalization, the shape of test feature: (7808, 64)\n",
            "After reshape, the shape of training feature: (1952, 16, 64) \n",
            "After reshape, the shape of test feature: (488, 16, 64)\n",
            "LSTM(\n",
            "  (lstm_layer): LSTM(64, 128, num_layers=2, batch_first=True)\n",
            "  (out): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n",
            "Epoch:  0 |train loss: 0.6795  train ACC: 0.5963 | test loss: 0.6819 test ACC: 0.5635 | AUC: 0.5955\n",
            "Epoch:  10 |train loss: 0.1324  train ACC: 0.9508 | test loss: 0.1596 test ACC: 0.9426 | AUC: 0.9821\n",
            "Epoch:  20 |train loss: 0.0619  train ACC: 0.9836 | test loss: 0.1583 test ACC: 0.9570 | AUC: 0.9843\n",
            "Epoch:  30 |train loss: 0.1438  train ACC: 0.9488 | test loss: 0.1818 test ACC: 0.9201 | AUC: 0.9847\n",
            "Epoch:  40 |train loss: 0.0179  train ACC: 0.9939 | test loss: 0.1115 test ACC: 0.9590 | AUC: 0.9942\n",
            "Epoch:  50 |train loss: 0.0095  train ACC: 0.9959 | test loss: 0.1240 test ACC: 0.9590 | AUC: 0.9950\n",
            "Epoch:  60 |train loss: 0.0099  train ACC: 0.9939 | test loss: 0.0764 test ACC: 0.9713 | AUC: 0.9969\n",
            "Epoch:  70 |train loss: 0.0096  train ACC: 0.9939 | test loss: 0.0811 test ACC: 0.9734 | AUC: 0.9969\n",
            "Epoch:  80 |train loss: 0.0101  train ACC: 0.9939 | test loss: 0.0732 test ACC: 0.9775 | AUC: 0.9976\n",
            "Epoch:  90 |train loss: 0.5995  train ACC: 0.6496 | test loss: 0.5612 test ACC: 0.7152 | AUC: 0.8267\n",
            "Epoch:  100 |train loss: 0.0625  train ACC: 0.9795 | test loss: 0.1244 test ACC: 0.9549 | AUC: 0.9911\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.95      0.96      0.96       250\n",
            "         1.0       0.96      0.95      0.95       238\n",
            "\n",
            "    accuracy                           0.95       488\n",
            "   macro avg       0.96      0.95      0.95       488\n",
            "weighted avg       0.96      0.95      0.95       488\n",
            "\n",
            "BEST TEST ACC: 0.9774590163934426, AUC: 0.9976134453781513\n",
            "Total Running Time: 164.49 seconds\n"
          ]
        }
      ]
    }
  ]
}